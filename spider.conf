#最大允许同时抓取的网页个数 
max_job_num= 30

#种子url，如果有多个，用逗号隔开 
#seeds=http://d.stulip.org/,http://blog.csdn.net/
seeds=http://d.stulip.org/

#允许的url域名                                          
include_prefixes=d.stulip.org
# 如果设置了守护进程，那么日志将会写入下列文件 
logfile=spiderq.log

# 日志的等级
#   0 DEBUG
#   1 INFO
#   2 WARN
#   3 ERROR
#   4 CRIT
log_level=0

#网页爬去允许的最大深度
max_depth=3

# 动态库文件所在目录
module_path=/etc/spider/modules/

#要载入的模块 
load_module=savehtml
load_module=saveimage
load_module=maxdepth
load_module=domainlimit

#接受的文件类型,html是默认 
accept_types=image/jpeg
